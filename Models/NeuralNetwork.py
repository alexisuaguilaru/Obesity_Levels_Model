import marimo

__generated_with = "0.14.12"
app = marimo.App()

with app.setup:
    # Importing auxiliar libraries

    import marimo as mo

    # Importing libraries

    from functools import partial
    from torch import nn , device , optim , Tensor
    from torch.cuda import is_available

    import pandas as pd
    from torch.utils.data import Dataset

    # Importing Functions and Utils

    import SourceModels as src


@app.cell
def _():
    # Defining useful variables

    PATH = './Models/'
    PATH_SAVE = PATH + 'SaveModels/'

    NUM_JOBS = src.GetNumJobs()
    TORCH_DEVICE = device('cuda' if is_available() else 'cpu')

    RANDOM_STATE = 8013
    return PATH, TORCH_DEVICE


@app.cell
def _():
    mo.md(r"""# Neural Network""")
    return


@app.cell
def _():
    mo.md(
        r"""
    La presnta libreta contiene el procedimiento y decisiones tomadas para crear una red neuronal usando [PyTorch](https://pytorch.org/) para la clasificación del nivel de obesidad de los pacientes en base a sus hábitos de vida. 

    En la sección [1. Load Dataset](#1-load-dataset) se carga los datasets de entrenamiento y evaluación del modelo haceiendo uso de las funcionalidades que ofrece PyTorch. 

    En la sección [2. Model Architecture](#2-model-architecture) se define la red neuronal para el clasificador, dando un efoque a ser una red simple y pequeña pero que sea capaz de aprender a clasificar los niveles de obesidad correctamente.

    Por último, en la sección [3. Model Training](#3-model-training) se optimizan los parámetros (pesos y bias) del modelo definido en la sección anterior usando el optimizador [Adam](https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html) y [CrossEntropyLoss](https://docs.pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) como función de pérdida.
    """
    )
    return


@app.cell
def _():
    mo.md("""# 1. Load Dataset""")
    return


@app.cell
def _():
    mo.md(r"""Subclassing of [`Dataset`](https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) is used to load the dataset so that it can be compatible with the neural networks in PyTorch. The [`DataLoader`](https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) used to train and evaluate the models are created in the `Trainer`. When loading the dataset, no normalization or scaling transformation is applied to the dataset.""")
    return


@app.cell
def _(PATH):
    # Splitting features 

    DatasetFilename = PATH + 'Dataset_{}.csv'
    _Dataset = pd.read_csv(DatasetFilename.format('Train'),nrows=1)

    NumericalFeatures , CategoricalFeatures , Target = src.SplitFeatures(_Dataset)
    Features = [*NumericalFeatures,*CategoricalFeatures]

    del _Dataset
    return DatasetFilename, Features, Target


@app.cell
def _(DatasetFilename, Features, Target):
    # Loading datasets

    Dataset_Train: Dataset = None
    Dataset_Evaluation: Dataset = None
    for _type_dataset in ['Train','Evaluation']:
        globals()[f'Dataset_{_type_dataset}'] = src.DatasetLoader(
            DatasetFilename.format(_type_dataset),
            Features,
            Target,
        )
    return Dataset_Evaluation, Dataset_Train


@app.cell
def _():
    mo.md(r"""# 2. Model Architecture""")
    return


@app.cell(hide_code=True)
def _():
    mo.md(r"""It makes use of a simple architecture with two hidden layers of $40$ and $25$ neurons, respectively, with `ReLU` activation functions.""")
    return


@app.class_definition
class NeuralNetwork(nn.Module):
    def __init__(self):
        """
        Neural network architecture for 
        predicting the obesity level of 
        a person
        """

        super().__init__()

        self.NN = nn.Sequential(
            nn.Linear(21,40),
            nn.ReLU(),
            nn.Linear(40,25),
            nn.ReLU(),
            nn.Linear(25,7),
        )

    def forward(
            self,
            Instance_X: Tensor
        ) -> Tensor:

        Logits = self.NN(Instance_X)
        return Logits


@app.cell
def _():
    mo.md(r"""# 3. Model Training""")
    return


@app.cell
def _():
    mo.md(
        r"""
    For the training of the neural network it was decided to use the optimizer [Adam](https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html), due to its robustness generated by its adaptive learning mechanisms, with a learning rate of $0.01$ and $50$ epochs with batch size of $32$ because there are not enough training instances (this setting was made by means of tests and empirical rules). 

    Para determinar el mejor modelo se hace uso de la métrica F1 con weighted average, esto debido al ligero imbalance del dataset respecto al target (`NObeyesdad`), como fue descrito en el
    """
    )
    return


@app.cell
def _():
    # Defining optimizer, loss function and metric

    _LearningRate = 1e-2
    Optimizer = partial(optim.Adam,lr=_LearningRate)

    LossFunction = nn.CrossEntropyLoss()
    MetricFunction = src.F1_NN()
    return LossFunction, MetricFunction, Optimizer


@app.cell
def _(LossFunction, Optimizer):
    # Initializing trainer of Neural Network

    NN_Trainer = src.NeuralNetworTrainer(
            NeuralNetwork,
            Optimizer,
            LossFunction,
        )
    return (NN_Trainer,)


@app.cell
def _(
    Dataset_Evaluation: Dataset,
    Dataset_Train: Dataset,
    MetricFunction,
    NN_Trainer,
    TORCH_DEVICE,
):
    # Training of neural network

    _Epochs = 50
    BatchSize = 32
    BestModel = NN_Trainer(
        Dataset_Train,
        Dataset_Evaluation,
        BatchSize,
        _Epochs,
        MetricFunction,
        TORCH_DEVICE
    )
    return


@app.cell
def _():
    # Saving best model

    # src.SaveModelNN(BestModel,PATH_SAVE,'NN')
    return


if __name__ == "__main__":
    app.run()
